# Toxic-Comment-Classification-using-BERT

The toxicity class refers to any comment or text containing offensive or hurtful words. This can involve insults, slurs or other offensive language.

## About the dataset :

We have a large number of Wikipedia comments which have been labelled by human raters for toxic behaviour. The dataset variables are:

1. toxic
2. severe_toxic
3. obscene
4. threat
5. insult
6. identity_hate
7. 
## Prerequisite :
### Install Pytorch 
```bash
 !pip install torch
```
### Install Transformer
```bash
!pip install transformers
```
